---
title: "Iteration HW"
author: "Bohan Zhu"
date: "2025-10-30"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE)
```

```{r}
library(tidyverse)
```

```{r,include=FALSE}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%",
  fig.retina = 2,
  dpi = 320
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

```{r}
set.seed(123)
```

## Problem 1: Same Birthday

Write the function

```{r}
bday_sim = function(n_room){
  
  birthdays = sample(1:365, n_room, replace = TRUE)
  
  repeated_bday = length(unique(birthdays)) < n_room 
  
  repeated_bday

}
```

Do the simulation

```{r}
bday_sim_results = 
  expand_grid(
    bdays = 2:50,
    iter = 1:10000
  ) |> 
  mutate(
    result = map_lgl(bdays, bday_sim)
  ) |> 
  group_by(
    bdays
  ) |> 
  summarize(
    prob_repeat = mean(result)
  )
```

plot this

```{r}
bday_sim_results |> 
  ggplot(aes(x = bdays, y = prob_repeat)) +
  geom_point() +
  geom_line()
```

## Problem 2 : Power in one sample t-test

Write the function
```{r}
t_test = function(mu){
  
  x = rnorm(30, mean = mu, sd = 5)
  broom::tidy(t.test(x, mu = 0, alternative = "two.sided")) |> 
    rename(mu_hat = estimate) |> 
    select(mu_hat, p.value)
  
}
```

Test for $\mu = 0$ only. 

```{r}
t_test_results = 
  expand_grid(
    mu = 0,
    iter = 1:5000
  ) |> 
  mutate(
    result = map(mu, t_test)
  ) |> 
  group_by(mu) |> 
  unnest(result)

t_test_results
```


Do the simulation for all $\mu$

```{r}
t_test_results = 
  expand_grid(
    mu = 0:6,
    iter = 1:5000
  ) |> 
  mutate(
    result = map(mu, t_test)
  ) |> 
  group_by(mu) |> 
  unnest(result)
```

plot 1: $\mu$ vs. power

```{r}
mu_power = 
  t_test_results |> 
  summarize(power = mean(p.value < 0.05))

mu_power |> 
  ggplot(aes(x = mu, y = power, color = mu)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = 1:6) +
  labs(
    x = "True mean mu",
    y = "Power (P(reject null))",
    title = "Relationship between Power and mu",
    caption = "Simulation results based on n = 30, sigma = 5, alpha = 0.05"
  ) +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5)
    )
```

There is a clear positive association between the effect size (the true mean $\mu$) and the power of the one-sample t-test.

When $\mu$ is close to 0, the test rarely rejects the null hypothesis because the sample mean does not differ much from 0. As  $\mu$ increases, the separation between the true mean and the null value grows, making it easier for the test statistic to exceed the critical threshold. As a result, the probability of rejecting the null hypothesis increases steadily.

In short, larger effect sizes produce higher power, approaching 1 when the true mean is sufficiently far from 0.

plot 2: $\mu$ vs. $\hat {\mu}$

```{r}
mu_summary_all <-
  t_test_results |>
  group_by(mu) |> 
  summarize(avg_mu_hat = mean(mu_hat))

mu_summary_sig <-
  t_test_results |>
  group_by(mu) |> 
  filter(p.value < 0.05) |>
  summarize(
    avg_mu_hat_sig = mean(mu_hat)
    )

mu_summary <-
  left_join(mu_summary_all, mu_summary_sig, by = "mu")
```

```{r}
mu_summary |> 
  ggplot(aes(x = mu)) +
  geom_point(aes(y = avg_mu_hat, color = "all mu included")) +
  geom_line(aes(y = avg_mu_hat, color = "all mu included")) +
  geom_point(aes(y = avg_mu_hat_sig, color = "significant mu only")) +
  geom_line(aes(y = avg_mu_hat_sig, color = "significant mu only"), 
            linetype = "dashed") +
  scale_x_continuous(breaks = 1:6) +
  labs(
    title = "Relationship between mu and mu_hat", 
    x = "True mean mu", 
    y = "Estimated mean mu_hat",
    caption = "Simulation results based on n = 30, sigma = 5, alpha = 0.05",
    color = ""
    ) +
  theme(
    legend.position = "right",
    plot.title = element_text(hjust = 0.5)
    )
```

From the plot, the overall average of $\hat{\mu}$ for all samples matches the true $\mu$.
This is expected, because the sample mean is an unbiased estimator of $\mu$, 
under the normal model. 

However, when we restrict attention only to samples where the null hypothesis was rejected, the average  $\hat{\mu}$ is noticeably higher than the true $\mu$, especially for small values of $\mu$ (see $\mu$ that are less than 2). 
This happens because rejection at $\alpha= 0.05$ selects samples where the sample mean deviates far enough from 0 to trigger significance. In other words, we are conditioning on a rare event that disproportionately includes samples with large positive deviations.

This selection creates an upward bias, making $\hat{\mu}$ appear larger than the truth. 
As $\mu$ increases and power approaches 1, almost all samples reject the null, so the bias gradually disappears

## Problem 3 Homicides

```{r}
homicides_df = 
  read_csv("data/homicide-data.csv", na = c("NA",".","")) |> 
  janitor::clean_names() 
```

```{r}
homicides_df =
  homicides_df |>
  mutate(
    city_state = str_c(city, ", ", state),
    unsolved_homicides = disposition %in% c("Closed without arrest", "Open/No arrest")
  ) |>
  group_by(city_state) |>
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved_homicides)
  ) |>
  ungroup()
```

`prop.test` for `Baltimore, MD` only

```{r}
city_prop_test = function(city_state_name) {

  city_chosen =
    homicides_df |>
    filter(city_state == city_state_name)

  prop_test =
    prop.test(
      x = city_chosen |> pull(unsolved_homicides),
      n = city_chosen |> pull(total_homicides)
    )

  
  broom::tidy(prop_test) |>
    select(estimate, conf.low, conf.high) |>
    mutate(city_state = city_state_name) |>
    select(city_state, everything())
}


city_prop_test("Baltimore, MD")
```

`prop.test` for all cities

```{r}
city_results =
  homicides_df |>
  mutate(
    prop_test = map2(unsolved_homicides, total_homicides, \(x, y) prop.test(x, y)),
    prop_tidy = map(prop_test, broom::tidy)
  ) |>
  unnest(prop_tidy) |>
  select(city_state, estimate, conf.low, conf.high, total_homicides)

prop_test_all =
  map_df(homicides_df$city_state, city_prop_test)

prop_test_all 
```

```{r}
prop_test_all|> 
  mutate(city_state = reorder(city_state, estimate)) |> 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
    geom_point()+
  theme(axis.text.x = element_text(size = 5,angle = 90))+
  ggtitle("Proportion of unsolved homicides in different cities")
```

